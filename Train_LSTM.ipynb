{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5g3QINuoPyL"
      },
      "source": [
        "#IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8pxb6zdn1i0",
        "outputId": "0a61d0a8-7bbc-49b9-b0dc-e4a57e9f6667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#librerie usate per l'analisi\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from datetime import datetime  \n",
        "import csv\n",
        "import os\n",
        "from os import listdir\n",
        "import json\n",
        "import csv\n",
        "import sys\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import RNN\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras.backend as K\n",
        "from keras import regularizers,optimizers\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import RepeatedKFold \n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn import tree\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "np.random.seed(2018)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PuYVc_wn7-b",
        "outputId": "bfd761d7-a959-46ae-d826-990f857ddc8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive = '/content/gdrive/My Drive/PaperGiugno/'\n",
        "path_db = drive + 'db_blackblaze'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPAiKwid59Zt"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vDQvLZl6xX2"
      },
      "source": [
        "def computeDay(group):\n",
        "  group = group.sort_values('date')    #ordino in base ai giorni... dal pi√π recente al meno\n",
        "  group['DayToFailure'] = list(range(group.shape[0]-1, -1,-1 ))\n",
        "  return group\n",
        "\n",
        "def divideInLevel(x):\n",
        "  if x.Label == 0:\n",
        "    return 'Good' #Good\n",
        "  elif x.DayToFailure <= 9:\n",
        "    return 'Alert' # Alert \n",
        "  elif x.DayToFailure <= 21:\n",
        "    return 'Warning ' #Warning \n",
        "  else:\n",
        "    return 'Very Fair'\n",
        "\n",
        "\n",
        "\n",
        "def tolerance_acc(x):\n",
        "  if x.pred == 'c_Good':\n",
        "    return x.vero == 'c_Good' or x.vero == 'c_Very Fair'\n",
        "  \n",
        "  if x.pred == 'c_Very Fair':\n",
        "    return x.vero == 'c_Good' or x.vero == 'c_Very Fair' or x.vero == 'c_Warning'\n",
        "  \n",
        "  if x.pred == 'c_Warning':\n",
        "    return  x.vero == 'c_Very Fair' or x.vero == 'c_Warning' or x.vero == 'c_Alert' \n",
        "  \n",
        "  if x.pred == 'c_Alert':\n",
        "    return  x.vero == 'c_Warning' or x.vero == 'c_Alert' \n",
        "\n",
        "\n",
        "def binary_classification_pred(x):\n",
        "  if x.pred == 'c_Good'  or x.pred == 'c_Very Fair':\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "    \n",
        "  \n",
        "def binary_classification_label(x):\n",
        "  if x.vero == 'c_Good'  or x.vero == 'c_Very Fair':\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "  n_vars = data.shape[1]\n",
        "  cols, names = list(), list()\n",
        "  dataclass = data[data.columns[-1:]]\n",
        "  data = data.drop(columns= ['serial_number', 'Class'], axis = 1)\n",
        "  columns = data.columns\n",
        "  # input sequence (t-n, ... t-1)  #non arrivo all'osservazione corrente\n",
        "  for i in range(n_in-1, 0, -1):\n",
        "    cols.append(data.shift(i))\n",
        "    names += [(element + '(t-%d)' % (i)) for element in columns]\n",
        "    \n",
        "  for i in range(0, n_out):\n",
        "    cols.append(data.shift(-i))\n",
        "    if i == 0:\n",
        "      names += [(element+'(t)') for element in columns]\n",
        "    else:\n",
        "      names += [(element +'(t+%d)' % (i)) for element in columns]\n",
        "  \n",
        "  cols.append(dataclass)   #appendo le ultime cinque colonne\n",
        "  names += ['Class']\n",
        "    \n",
        "  agg = pd.concat(cols, axis=1)\n",
        "  agg.columns = names\n",
        "  if dropnan:\n",
        "    agg.dropna(inplace=True)\n",
        "  \n",
        "  return agg\n",
        "\n",
        "\n",
        "def balancing_by_replication(X_train):\n",
        "  \n",
        "  alert = X_train[X_train.c_Alert == 1] \n",
        "  vfair = X_train[X_train['c_Very Fair'] == 1]\n",
        "  warn =  X_train[X_train.c_Warning == 1]\n",
        "  #'c_Alert','c_Good','c_Very Fair','c_Warning'\n",
        "  good = X_train[X_train.c_Good == 1] # sono i buoni\n",
        "\n",
        "  size_good = good.shape[0]\n",
        "\n",
        "  while alert.shape[0] < size_good:\n",
        "    app = alert.sample(min(alert.shape[0], size_good - alert.shape[0]), replace=False)\n",
        "    alert = alert.append(app)\n",
        "\n",
        "  while vfair.shape[0] < size_good:\n",
        "    app = vfair.sample(min(vfair.shape[0], size_good - vfair.shape[0]), replace=False)\n",
        "    vfair = vfair.append(app)\n",
        "  \n",
        "  while warn.shape[0] < size_good:\n",
        "    app = warn.sample(min(warn.shape[0], size_good - warn.shape[0]), replace=False)\n",
        "    warn = warn.append(app)\n",
        "\n",
        "  \n",
        "  good = good.append(alert)\n",
        "  good = good.append(vfair)\n",
        "  good = good.append(warn)\n",
        "  return good \n",
        "\n",
        "\t\t\t  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS1HtLg7PIwU"
      },
      "source": [
        "#Pre- processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PTfLJxYXhPJ"
      },
      "source": [
        "listLabels = ['c_Alert','c_Good','c_Very Fair','c_Warning']\n",
        "finestra = 14\n",
        "df= pd.read_csv(path_db+ '/'+'BalckDaUsare.csv',sep=';')\n",
        "df.date = pd.to_datetime(df.date, format='%Y-%m-%d').dt.date\n",
        "df = df.drop(['CurrentPendingSectorCount','ReallocatedSectorsCount'], axis=1)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range = (-1,1))\n",
        "df[['ReportedUncorrectableErrors', 'HighFlyWrites', 'TemperatureCelsius', \n",
        "    'RawCurrentPendingSectorCount','RawReadErrorRate', 'SpinUpTime', \n",
        "    'RawReallocatedSectorsCount', 'SeekErrorRate', 'PowerOnHours']] = scaler.fit_transform(df[['ReportedUncorrectableErrors', \n",
        "                                                                                               'HighFlyWrites', 'TemperatureCelsius', \n",
        "                                                                                               'RawCurrentPendingSectorCount',\n",
        "                                                                                               'RawReadErrorRate', 'SpinUpTime', \n",
        "                                                                                               'RawReallocatedSectorsCount', \n",
        "                                                                                               'SeekErrorRate', 'PowerOnHours']])\n",
        "\n",
        "dfHour = df.groupby(['serial_number']).apply(computeDay)\n",
        "dfHour = dfHour[dfHour.DayToFailure <= 45]\n",
        "dfHour = dfHour.drop(columns = ['date'])\n",
        "dfHour['Class'] = dfHour.apply(divideInLevel, axis=1)\n",
        "dfHour= dfHour.drop(columns= ['Label','DayToFailure', 'serial_number'], axis=1)\n",
        "dfHour=dfHour.reset_index()\n",
        "dfHour= dfHour.drop(columns= ['level_1'], axis=1)\n",
        "\n",
        "#creo le sequenze\n",
        "print('Creazione Sequenze')\n",
        "dfHourSequence =  dfHour.groupby(['serial_number']).apply(series_to_supervised, n_in=finestra, n_out=1, dropnan=True)\n",
        "dfHourSequence = pd.concat([dfHourSequence, pd.get_dummies(dfHourSequence.Class,prefix='c')], axis=1).drop(['Class'],axis=1)\n",
        "numberClasses = len(listLabels)\n",
        "\n",
        "#divisione in train validation e split\n",
        "X_train, X_rim, y_train, y_rim = train_test_split(dfHourSequence[dfHourSequence.columns[:-numberClasses]], \n",
        "                                                  dfHourSequence[dfHourSequence.columns[-numberClasses:]] ,\n",
        "                                                  stratify=dfHourSequence[dfHourSequence.columns[-numberClasses:]], \n",
        "                                                  test_size=0.30)\n",
        "\n",
        "print(y_train.sum())\n",
        "print(y_train.columns)\n",
        "del dfHourSequence\n",
        "del dfHour\n",
        "\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_rim, y_rim ,stratify=y_rim, test_size=0.50)\n",
        "\n",
        "\n",
        "del X_rim\n",
        "del y_rim\n",
        "X_train = pd.concat([X_train, pd.DataFrame(columns = listLabels)], sort = True)\n",
        "X_val = pd.concat([X_val,  pd.DataFrame(columns = listLabels)], sort = True)\n",
        "X_test = pd.concat([X_test, pd.DataFrame(columns = listLabels)], sort = True)\n",
        "\n",
        "X_train[listLabels] = y_train.values\n",
        "X_val[listLabels] = y_val.values\n",
        "X_test[listLabels] = y_test.values\n",
        "\n",
        "\n",
        "del y_train\n",
        "del y_val\n",
        "del y_test\n",
        "\n",
        "\n",
        "\n",
        "print('Balancing')\n",
        "Complete_train  = balancing_by_replication(X_train)\n",
        "print(Complete_train.shape)\n",
        "del X_train\n",
        "\n",
        "print(X_val.groupby(listLabels).count())\n",
        "Complete_val = balancing_by_replication(X_val)\n",
        "print(Complete_val.shape)\n",
        "del X_val\n",
        "\n",
        "#tolgo le label\n",
        "ytrain = Complete_train[listLabels].values\n",
        "print(Complete_train[listLabels].sum())\n",
        "Xtrain = Complete_train.drop(columns=listLabels, axis=1 )\n",
        "\n",
        "\n",
        "yVal = Complete_val[listLabels].values\n",
        "print(Complete_val[listLabels].sum())\n",
        "Xval = Complete_val.drop(columns=listLabels, axis=1 )\n",
        "\n",
        "yTest = X_test[listLabels].values\n",
        "Xtest = X_test.drop(columns=listLabels, axis=1 )\n",
        "\n",
        "\n",
        "#reshape come sequenze\n",
        "Xtrain = Xtrain.values.reshape(Xtrain.shape[0], finestra, int(Xtrain.shape[1]/finestra))\n",
        "Xval = Xval.values.reshape(Xval.shape[0], finestra, int(Xval.shape[1]/finestra))\n",
        "Xtest= Xtest.values.reshape(Xtest.shape[0], finestra, int(Xtest.shape[1]/finestra))\n",
        "\n",
        "print(Xtrain.shape)\n",
        "print(Xval.shape)\n",
        "print(Xtest.shape)\n",
        "\n",
        "print(ytrain.shape)\n",
        "print(yVal.shape)\n",
        "print(yTest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbxFyEM5sk7p"
      },
      "source": [
        "#Modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV8OcQJSskfx"
      },
      "source": [
        "def build_model():\n",
        "  dp_lvl = 0.1\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, input_shape=(finestra, 9), return_sequences =  True ))\n",
        "  model.add(LSTM(128, return_sequences =  False))\n",
        "  model.add(Dense(numberClasses, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Twd9xyqspRC"
      },
      "source": [
        "#Addestramento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCzPsRLbssiA"
      },
      "source": [
        "epoche = 150\n",
        "historyvet =[]\n",
        "model = build_model()    \n",
        "best_acc= 0.0\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0,amsgrad=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "for epoch in range(0,epoche):\n",
        "  print('Epoch {%d}' %(epoch))\n",
        "  history = model.fit(Xtrain, ytrain, epochs=1, batch_size=500, validation_data= (Xval,yVal), shuffle=True)\n",
        "  if (history.history['val_accuracy'][0] > best_acc ):\n",
        "    print('Update best model')\n",
        "    best_acc = history.history['val_accuracy'][0]\n",
        "    best_epoch  = epoch\n",
        "    model.save('best_model.h5')\n",
        "    \n",
        "  historyvet.append(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXEm3sPCdxe6"
      },
      "source": [
        "#Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1zr0l_jsvFR"
      },
      "source": [
        "lossTrain=[]\n",
        "lossval=[]\n",
        "accTrain = []\n",
        "accVal =[]\n",
        "\n",
        "for element in historyvet:\n",
        "   lossTrain.append(element['loss'][0])\n",
        "   lossval.append(element['val_loss'][0])\n",
        "   accTrain.append(element['accuracy'][0])\n",
        "   accVal.append(element['val_accuracy'][0])\n",
        "  \n",
        "\n",
        "plt.plot(lossTrain, color='g')\n",
        "plt.plot(lossval, color='r')\n",
        "plt.title('model loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(accTrain, color='g')\n",
        "plt.plot(accVal, color='r')\n",
        "plt.title('model Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsF8fBqeszNR"
      },
      "source": [
        "#Fine tuning on val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFkOheSCsyfF"
      },
      "source": [
        "newModel = load_model( 'best_model.h5')\n",
        "adam = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "newModel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "newModel.summary()\n",
        "epoche = 25\n",
        "\n",
        "historyRiadd = newModel.fit(Xval,yVal, epochs=epoche, batch_size=1024, shuffle=True)\n",
        "newModel.save('Final_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Ajf7xwd3VE"
      },
      "source": [
        "#Performance evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4ynIql7s4SL"
      },
      "source": [
        "print(newModel.evaluate(Xtest,yTest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsAiAvFCs5lT"
      },
      "source": [
        "pred = newModel.predict(Xtest)\n",
        "predpd = pd.DataFrame(pred, columns=listLabels)\n",
        "predpd= predpd.idxmax(axis=1)\n",
        "predpd = predpd.to_frame()\n",
        "\n",
        "ytestpd = pd.DataFrame(yTest, columns=listLabels)\n",
        "ytestpd= ytestpd.idxmax(axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alStEkohs7T9"
      },
      "source": [
        "acc2 = accuracy_score(ytestpd.values, predpd.values)\n",
        "print('Accuracy sul Test :', acc2)\n",
        "\n",
        "c=confusion_matrix(ytestpd.values, predpd.values)\n",
        "plt.figure(figsize=(12,12))\n",
        "ax = sns.heatmap(c, yticklabels=1, xticklabels=1, annot=True, fmt=\"d\", cbar=False)\n",
        "ax.figure.axes[-1].yaxis.label.set_size(20)\n",
        "ax.set_xlabel(\"Predicted Label\",fontsize=20)\n",
        "ax.set_ylabel(\"True Label\",fontsize=20)\n",
        "ax.tick_params(labelsize=13)\n",
        "ax.set_xticklabels(listLabels)\n",
        "ax.set_yticklabels(listLabels)\n",
        "plt.yticks(rotation=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkDCuZkSs9sq"
      },
      "source": [
        "predpd = predpd.rename(columns={predpd.columns[0]:'pred'})\n",
        "predpd['vero'] = ytestpd.values\n",
        "\n",
        "buoni = predpd[predpd.vero == 'c_Good']\n",
        "acc3 = accuracy_score(buoni.vero.values, buoni.pred.values)\n",
        "print('Accuracy sulle sequenze good: ', acc3)\n",
        "\n",
        "  \n",
        "failed = predpd[predpd.vero != 'c_Good']\n",
        "acc3 = accuracy_score(failed.vero.values, failed.pred.values)\n",
        "print('Accuracy sulle sequenze failed: ', acc3) \n",
        "\n",
        "  \n",
        "predpd['TOL']= predpd.apply(tolerance_acc, axis=1)\n",
        "predpd['TOL'] = predpd['TOL'].astype(int)\n",
        "\n",
        "buoni = predpd[predpd.vero == 'c_Good']\n",
        "prest = buoni.TOL.sum()/buoni.shape[0]\n",
        "print('Accuracy sulle sequenze good con tolleranza: ', prest)\n",
        "\n",
        "\n",
        "failed = predpd[predpd.vero != 'c_Good']\n",
        "prest = failed.TOL.sum()/failed.shape[0]\n",
        "print('Accuracy sulle sequenze failed con tolleranza: ', prest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_62OrzcTtApC"
      },
      "source": [
        "predpd['binaryLabelPred']= predpd.apply(binary_classification_pred, axis=1)\n",
        "predpd['binaryLabelTrue']= predpd.apply(binary_classification_label, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAVvawaWtB-L"
      },
      "source": [
        "x = predpd[predpd.binaryLabelTrue ==1].binaryLabelTrue.count()\n",
        "y = predpd[(predpd.binaryLabelTrue ==1) & (predpd.binaryLabelPred ==1) ].binaryLabelTrue.count()\n",
        "\n",
        "FDR = y/x\n",
        "print('FDR ', FDR)\n",
        "\n",
        "x = predpd[predpd.binaryLabelTrue ==0].binaryLabelTrue.count()\n",
        "y = predpd[(predpd.binaryLabelTrue ==0) & (predpd.binaryLabelPred ==1) ].binaryLabelTrue.count()\n",
        "\n",
        "FAR = y/x\n",
        "print('FAR ', FAR)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}